{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Monta il drive per non perdere l'output"
      ],
      "metadata": {
        "id": "KzCCbVL2xnbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Monta Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NndLtnfoxmBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5nagEQZrLbp"
      },
      "outputs": [],
      "source": [
        "#!conda create --name pem python=3.10 -y\n",
        "#!conda activate pem\n",
        "\n",
        "#!conda install pytorch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 cudatoolkit=11.3 -c pytorch\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "!git clone https://github.com/NiccoloCavagnero/PEM.git\n",
        "import os\n",
        "\n",
        "# Ottieni il percorso corrente\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "\n",
        "# Cambia directory\n",
        "os.chdir('PEM')\n",
        "\n",
        "# Ottieni il nuovo percorso\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scarico il dataset"
      ],
      "metadata": {
        "id": "ijx_M8RE_GSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Ottieni il percorso corrente\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "\n",
        "# Cambia directory\n",
        "os.chdir('datasets')\n",
        "\n",
        "# Ottieni il nuovo percorso\n",
        "current_path = os.getcwd()\n",
        "print(current_path)"
      ],
      "metadata": {
        "id": "Oga3B2sN9CoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import zipfile\n",
        "import subprocess\n",
        "\n",
        "# Funzione per scaricare un file e decomprimerlo\n",
        "def download_and_extract(url, zip_path, extract_path):\n",
        "    # Se il file ZIP esiste già, non scaricarlo di nuovo\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Downloading {url} to {zip_path}...\")\n",
        "        # Scarica il file usando curl\n",
        "        try:\n",
        "            subprocess.run([\"curl\", \"-L\", \"-o\", zip_path, url], check=True)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error downloading file: {e}\")\n",
        "            return\n",
        "\n",
        "    # Crea la directory di estrazione se non esiste\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "    # Estrai il file ZIP\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f\"Extracted files to {extract_path}\")\n",
        "    except zipfile.BadZipFile as e:\n",
        "        print(f\"Error extracting {zip_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    # Elenca i file estratti\n",
        "    extracted_files = os.listdir(extract_path)\n",
        "    print(f\"Extracted files in {extract_path}:\", extracted_files)\n",
        "\n",
        "# Percorsi principali\n",
        "base_dir = os.path.expanduser(\"loveDa_zipped\")\n",
        "\n",
        "# Crea la directory base se non esiste\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Dataset Val\n",
        "val_url = \"https://zenodo.org/records/5706578/files/Val.zip?download=1\"\n",
        "val_zip_path = os.path.join(base_dir, \"Val.zip\")\n",
        "val_extract_path = os.path.join(base_dir, \"\")\n",
        "download_and_extract(val_url, val_zip_path, val_extract_path)\n",
        "\n",
        "# Dataset Train\n",
        "train_url = \"https://zenodo.org/records/5706578/files/Train.zip?download=1\"\n",
        "train_zip_path = os.path.join(base_dir, \"Train.zip\")\n",
        "train_extract_path = os.path.join(base_dir, \"\")\n",
        "download_and_extract(train_url, train_zip_path, train_extract_path)"
      ],
      "metadata": {
        "id": "MfjMTINy7fPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatto il dataset come richiesto\n",
        "LOVEDA\n",
        "├───Test\n",
        "│   ├───Rural\n",
        "│   │   └───images_png\n",
        "│   └───Urban\n",
        "│       └───images_png\n",
        "├───Train\n",
        "│   ├───Rural\n",
        "│   │   ├───images_png\n",
        "│   │   └───masks_png\n",
        "│   └───Urban\n",
        "│       ├───images_png\n",
        "│       └───masks_png\n",
        "└───Val\n",
        "    ├───Rural\n",
        "    │   ├───images_png\n",
        "    │   └───masks_png\n",
        "    └───Urban\n",
        "        ├───images_png\n",
        "        └───masks_png\n",
        "\n",
        "in\n",
        "loveDa\n",
        "    ├───train\n",
        "    │   ├───annotations // mask contenute in Train/Urban/mask_png\n",
        "    │   └───images // immagini contenute in Train/Urban/images_png\n",
        "    ├───val\n",
        "    │   ├───annotations  // mask contenute in Val/Urban/mask_png\n",
        "    │   └───images  // immagini contenute in Val/Urban/images_png\n",
        "    └───val_rural\n",
        "        ├───annotations  // mask contenute in Val/Rural/mask_png\n",
        "        └───images   // immagini contenute in Val/Rural/images_png"
      ],
      "metadata": {
        "id": "T4CM-kFZ_L0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def reorganize_loveda(source_dir, target_dir):\n",
        "    # Crea le directory principali\n",
        "    splits = {\n",
        "        'train': ['Urban'],\n",
        "        'val': ['Urban'],\n",
        "        'val_rural': ['Rural']\n",
        "    }\n",
        "\n",
        "    for split, areas in splits.items():\n",
        "        # Crea le sottodirectory per ogni split\n",
        "        (Path(target_dir) / split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "        (Path(target_dir) / split / 'annotations').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for area in areas:\n",
        "            # Source paths\n",
        "            if split == 'val_rural':\n",
        "                src_split = 'Val'\n",
        "            elif split == 'val':\n",
        "                src_split = 'Val'\n",
        "            else:\n",
        "                src_split = 'Train'\n",
        "\n",
        "            src_img = Path(source_dir) / src_split / area / 'images_png'\n",
        "            src_mask = Path(source_dir) / src_split / area / 'masks_png'\n",
        "\n",
        "            # Target paths\n",
        "            dst_img = Path(target_dir) / split / 'images'\n",
        "            dst_mask = Path(target_dir) / split / 'annotations'\n",
        "\n",
        "            # Copia le immagini\n",
        "            if src_img.exists():\n",
        "                for img in src_img.glob('*'):\n",
        "                    shutil.copy2(img, dst_img / img.name)\n",
        "\n",
        "            # Copia le maschere se esistono\n",
        "            if src_mask.exists():\n",
        "                for mask in src_mask.glob('*'):\n",
        "                    shutil.copy2(mask, dst_mask / mask.name)\n",
        "\n",
        "    # Elimina la directory sorgente dopo la copia\n",
        "    shutil.rmtree(source_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    source_directory = \"loveDa_zipped\"  # Directory sorgente\n",
        "    target_directory = \"loveDa\"  # Directory destinazione\n",
        "\n",
        "    reorganize_loveda(source_directory, target_directory)\n"
      ],
      "metadata": {
        "id": "J3XyHwUw86xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ottieni il percorso corrente\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "\n",
        "# Cambia directory\n",
        "os.chdir('..')\n",
        "\n",
        "# Ottieni il nuovo percorso\n",
        "current_path = os.getcwd()\n",
        "print(current_path)"
      ],
      "metadata": {
        "id": "sXFduVLC9pWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inserisci la cartella loveDa in config dalla repo nostra, loveDa.py in datasets e sostituire train_net.py con quello nella nostra repo\n"
      ],
      "metadata": {
        "id": "3MZBy40u9vAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Martons00/ToolsPEM_loveDa"
      ],
      "metadata": {
        "id": "7bYw70DPqFE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Definizione dei percorsi corretti partendo da PEM\n",
        "source_folder = 'ToolsPEM_loveDa/loveDa'\n",
        "config_dest = 'configs'\n",
        "dataset_source = 'ToolsPEM_loveDa/loveDa.py'\n",
        "dataset_dest = 'datasets'\n",
        "train_source = 'ToolsPEM_loveDa/train_net_loveDa.py'\n",
        "train_dest = ''\n",
        "\n",
        "# Copia la cartella loveDA in configs\n",
        "shutil.copytree(source_folder, os.path.join(config_dest, 'loveDa'), dirs_exist_ok=True)\n",
        "\n",
        "# Copia il file loveDA.py in datasets\n",
        "shutil.copy2(dataset_source, dataset_dest)\n",
        "\n",
        "# Copia train_net_loveDa.py nella root di PEM\n",
        "shutil.copy2(train_source, train_dest)\n",
        "\n"
      ],
      "metadata": {
        "id": "s30vsjAJr4uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "# Ottieni il percorso corrente\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "\n",
        "\n",
        "# Crea la directory per i modelli pre-addestrati\n",
        "os.makedirs('pretrained_models', exist_ok=True)\n",
        "os.chdir('pretrained_models')\n",
        "\n",
        "# Download dei modelli usando gdown\n",
        "\n",
        "!gdown 1DFoXcV42zy-apUcMh5P8WhsXMRJofgl8\n",
        "!gdown 1Y5belNkq3Dn-EYgSKY-ICiPsN4TZXoXO\n",
        "\n",
        "# Converti i modelli\n",
        "!python ../tools/convert-pretrained-stdc-model-to-d2.py STDCNet813M_73.91.tar STDC1.pkl\n",
        "!python ../tools/convert-pretrained-stdc-model-to-d2.py STDCNet1446_76.47.tar STDC2.pkl\n",
        "\n",
        "# Torna alla directory principale\n",
        "os.chdir('..')\n"
      ],
      "metadata": {
        "id": "h_ARX9Wa-hog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# Clear cache\n",
        "torch.cuda.empty_cache()\n",
        "# Collect garbage\n",
        "gc.collect()\n",
        "# Check allocated memory\n",
        "print(torch.cuda.memory_allocated() / 1024**2, \"MB\")\n",
        "# Check cached memory\n",
        "print(torch.cuda.memory_cached() / 1024**2, \"MB\")\n",
        "\n",
        "\n",
        "!python train_net.py \\\n",
        "       --config-file ./configs/loveDa/semantic-segmentation/pem_R50_bs32_90k.yaml \\\n",
        "       --num-gpus 1 \\\n",
        "       DATALOADER.NUM_WORKERS 0"
      ],
      "metadata": {
        "id": "FAvbeA-n-k-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa le librerie necessarie\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Definisci i percorsi\n",
        "source_path = '/content/PEM/output'  # Percorso della cartella locale in Colab\n",
        "destination_path = '/content/drive/My Drive/PEM'  # Percorso destinazione su Drive\n",
        "\n",
        "# Crea la cartella di destinazione se non esiste\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Copia la cartella e tutto il suo contenuto\n",
        "shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n",
        "# Verifica i file copiati\n",
        "!ls \"/content/drive/My Drive/PEM\""
      ],
      "metadata": {
        "id": "RRk8SKTXxCcI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}